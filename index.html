<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Deepfake Detection, Audio-Visual">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Directionality-aware audio-visual deepfake detection considering cross-modal asymmetry</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <h1 class="title is-1 publication-title">Directionality-aware Audio-Visual Deepfake Detection Considering Cross-modal Asymmetry</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jun Hee Lee<sup>1</sup>,</span>
            <span class="author-block">
              Jung Uk Kim†<sup>1</sup></span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of Computer Engineering, Kyung Hee University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="./static/paper/Final_Report.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/wnsgmllee/AVDFD"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <span class="link-block">
                <a href="./static/slides/Final_Presentation.pptx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-chalkboard-teacher"></i>
                  </span>
                  <span>Slides</span>
                </a>
              </span>

              <span class="link-block">
                <a href="./static/videos/Final_Presentation.mp4"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-video"></i>
                  </span>
                  <span>Presentation</span>
                </a>
              </span>


            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- =========================
     Framework (replaces all content before Abstract)
     - Place the image at: ./static/images/framework.jpg
     ========================= -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image">
          <img src="./static/images/framework.png" alt="Overall framework">
        </figure>
        <p class="has-text-centered" style="margin-top: 0.75\rem;">
          Overall Framework
        </p>
      </div>
    </div>
  </div>
</section>


<!-- =========================
     Abstract (kept unchanged)
     ========================= -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            기존 오디오-비주얼 딥페이크 탐지는 모달리티 간 동기화 불일치에 주로 의존하며, 오디오와 비
주얼을 대칭적으로 정렬하거나 상호 복원해 일대일 대응을 강제해왔다. 그러나 실제 발화에서 두 
모달리티 관계는 비대칭적이며, 특히 비주얼만으로 오디오를 예측하는 방향은 본질적으로 불안정
하다. 본 연구는 이를 해결하기 위해 오디오를 기준으로 비주얼의 정합성을 검증하는 방향성 기반 
단방향 프레임워크를 제안한다. 먼저 오디오 단일 모달리티 representation learning으로 생성 
흔적에 강건한 오디오 인코더를 학습하고, 이후 오디오 조건으로 시점별 비주얼 표현을 예측해 실
제 비주얼 표현과의 불일치를 탐지 신호로 사용한다. 또한 오디오 단서와 모달리티 정합 단서를 
신뢰도 기반으로 융합해 샘플별로 더 강한 단서에 가중치를 부여한다. 실험 결과 오디오만으로도 
높은 탐지 성능을 보였고, 멀티모달 결합 시 성능이 추가로 향상되어, 동기화 단서가 약한 고난도 
조건에서도 제안한 방향성 모델링이 효과적임을 확인하였다.
          </p>

        </div>
      </div>
    </div>
  </div>
</section>


</body>
</html>
